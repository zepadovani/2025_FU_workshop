{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéµ Machine Listening Workshop - Demo\n",
    "\n",
    "Welcome to the **Machine Listening** workshop! This notebook demonstrates audio processing and analysis using Python.\n",
    "\n",
    "## üì¶ Environment Setup\n",
    "\n",
    "First, let's set up the environment automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detects if running on Colab and installs dependencies\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"üåê Running on Google Colab\")\n",
    "    \n",
    "    # Repository URL\n",
    "    REPO_URL = \"https://raw.githubusercontent.com/zepadovani/2025_FU_workshop/main\"\n",
    "    REQUIREMENTS_URL = f\"{REPO_URL}/requirements.txt\"\n",
    "    \n",
    "    print(\"\\nüì¶ Installing dependencies...\")\n",
    "    \n",
    "    # Tries to download and install from requirements.txt\n",
    "    try:\n",
    "        subprocess.run([\"wget\", \"-q\", REQUIREMENTS_URL, \"-O\", \"requirements.txt\"], check=True)\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", \"requirements.txt\"], check=True)\n",
    "        print(\"‚úÖ Dependencies installed from requirements.txt\")\n",
    "    except:\n",
    "        # Fallback: manual installation\n",
    "        print(\"‚ö†Ô∏è  Installing packages manually...\")\n",
    "        packages = [\"librosa\", \"soundfile\", \"gradio\", \"matplotlib\"]\n",
    "        for pkg in packages:\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg], check=True)\n",
    "            print(f\"  ‚úì {pkg}\")\n",
    "        print(\"‚úÖ Installation complete\")\n",
    "    \n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"üíª Running locally (using Pixi environment)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Import Libraries\n",
    "\n",
    "Now let's import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import gradio as gr\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"Librosa version: {librosa.__version__}\")\n",
    "print(f\"Gradio version: {gr.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéº Generate Synthetic Audio\n",
    "\n",
    "Let's create an example audio for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "sample_rate = 22050\n",
    "duration = 2.0  # seconds\n",
    "frequency = 440  # Hz (A note)\n",
    "\n",
    "# Generates a sine tone\n",
    "t = np.linspace(0, duration, int(sample_rate * duration))\n",
    "audio_signal = 0.5 * np.sin(2 * np.pi * frequency * t)\n",
    "\n",
    "# Adds a fade in/out\n",
    "fade_samples = int(0.1 * sample_rate)\n",
    "audio_signal[:fade_samples] *= np.linspace(0, 1, fade_samples)\n",
    "audio_signal[-fade_samples:] *= np.linspace(1, 0, fade_samples)\n",
    "\n",
    "print(f\"‚úÖ Audio generated: {duration}s @ {sample_rate} Hz\")\n",
    "print(f\"   Frequency: {frequency} Hz\")\n",
    "print(f\"   Shape: {audio_signal.shape}\")\n",
    "\n",
    "# Plays the audio\n",
    "display(Audio(audio_signal, rate=sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Spectral Analysis\n",
    "\n",
    "Let's visualize the audio spectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the STFT (Short-Time Fourier Transform)\n",
    "D = librosa.stft(audio_signal)\n",
    "S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "\n",
    "# Visualizes the spectrogram\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.specshow(S_db, x_axis='time', y_axis='hz', sr=sample_rate, cmap='viridis')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Spectrogram')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Spectrogram shape: {S_db.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Feature Analysis\n",
    "\n",
    "Let's extract audio features using Librosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration\n",
    "duration_calc = librosa.get_duration(y=audio_signal, sr=sample_rate)\n",
    "\n",
    "# Tempo (BPM) - for a pure tone, might not be very meaningful\n",
    "tempo, beats = librosa.beat.beat_track(y=audio_signal, sr=sample_rate)\n",
    "\n",
    "# Zero Crossing Rate\n",
    "zcr = librosa.feature.zero_crossing_rate(audio_signal)\n",
    "\n",
    "# Spectral Centroid\n",
    "spectral_centroids = librosa.feature.spectral_centroid(y=audio_signal, sr=sample_rate)\n",
    "\n",
    "# MFCCs\n",
    "mfccs = librosa.feature.mfcc(y=audio_signal, sr=sample_rate, n_mfcc=13)\n",
    "\n",
    "print(\"üìä Extracted Features:\")\n",
    "print(f\"  Duration: {duration_calc:.2f}s\")\n",
    "print(f\"  Tempo: {tempo:.2f} BPM\")\n",
    "print(f\"  Zero Crossing Rate (mean): {zcr.mean():.4f}\")\n",
    "print(f\"  Spectral Centroid (mean): {spectral_centroids.mean():.2f} Hz\")\n",
    "print(f\"  MFCCs shape: {mfccs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Interactive Gradio Interface\n",
    "\n",
    "Let's create an interactive web interface with Gradio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_audio(audio_input):\n",
    "    \"\"\"\n",
    "    Analyzes an audio file and returns information + spectrogram.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Process input\n",
    "        if isinstance(audio_input, tuple):\n",
    "            sr, y = audio_input\n",
    "            # Convert to mono if necessary\n",
    "            if len(y.shape) > 1:\n",
    "                y = np.mean(y, axis=1)\n",
    "            # Normalize\n",
    "            y = y.astype(np.float32)\n",
    "            if y.max() > 1.0:\n",
    "                y = y / np.iinfo(np.int16).max\n",
    "        else:\n",
    "            y, sr = librosa.load(audio_input, sr=None)\n",
    "        \n",
    "        # Analysis\n",
    "        duration = librosa.get_duration(y=y, sr=sr)\n",
    "        tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y).mean()\n",
    "        centroid = librosa.feature.spectral_centroid(y=y, sr=sr).mean()\n",
    "        \n",
    "        # Spectrogram\n",
    "        D = librosa.stft(y)\n",
    "        S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 4))\n",
    "        librosa.display.specshow(S_db, x_axis='time', y_axis='hz', sr=sr, ax=ax, cmap='viridis')\n",
    "        fig.colorbar(ax.collections[0], ax=ax, format='%+2.0f dB')\n",
    "        ax.set_title('Spectrogram')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Textual result\n",
    "        result = f\"\"\"\n",
    "### ‚úÖ Analysis Complete!\n",
    "\n",
    "**üìä Information:**\n",
    "- Duration: {duration:.2f}s\n",
    "- Sample Rate: {sr} Hz\n",
    "- Estimated Tempo: {tempo:.2f} BPM\n",
    "- Zero Crossing Rate: {zcr:.4f}\n",
    "- Spectral Centroid: {centroid:.2f} Hz\n",
    "        \"\"\"\n",
    "        \n",
    "        return result, fig\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error: {str(e)}\", None\n",
    "\n",
    "\n",
    "# Create interface\n",
    "with gr.Blocks(title=\"Machine Listening Demo\") as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üéµ Machine Listening - Interactive Demo\n",
    "    Upload an audio file or record using your microphone!\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        audio_input = gr.Audio(label=\"Audio\", type=\"filepath\", sources=[\"upload\", \"microphone\"])\n",
    "    \n",
    "    analyze_btn = gr.Button(\"üîç Analyze\", variant=\"primary\")\n",
    "    \n",
    "    text_output = gr.Markdown()\n",
    "    plot_output = gr.Plot()\n",
    "    \n",
    "    analyze_btn.click(\n",
    "        fn=analyze_audio,\n",
    "        inputs=audio_input,\n",
    "        outputs=[text_output, plot_output]\n",
    "    )\n",
    "\n",
    "# Launch interface (share=True for public link on Colab)\n",
    "demo.launch(share=IN_COLAB)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
