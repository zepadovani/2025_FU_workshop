{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83c\udfb5 Machine Listening Workshop - Demo\n",
    "\n",
    "Bem-vindo ao workshop de **Machine Listening**! Este notebook demonstra processamento de \u00e1udio e an\u00e1lise usando Python.\n",
    "\n",
    "## \ud83d\udce6 Setup do Ambiente\n",
    "\n",
    "Primeiro, vamos configurar o ambiente automaticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecta se est\u00e1 no Colab e instala depend\u00eancias\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"\ud83c\udf10 Rodando no Google Colab\")\n",
    "    \n",
    "    # URL do reposit\u00f3rio\n",
    "    REPO_URL = \"https://raw.githubusercontent.com/zepadovani/2025_FU_workshop/main\"\n",
    "    REQUIREMENTS_URL = f\"{REPO_URL}/requirements.txt\"\n",
    "    \n",
    "    print(\"\\n\ud83d\udce6 Instalando depend\u00eancias...\")\n",
    "    \n",
    "    # Tenta baixar e instalar do requirements.txt\n",
    "    try:\n",
    "        subprocess.run([\"wget\", \"-q\", REQUIREMENTS_URL, \"-O\", \"requirements.txt\"], check=True)\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", \"requirements.txt\"], check=True)\n",
    "        print(\"\u2705 Depend\u00eancias instaladas do requirements.txt\")\n",
    "    except:\n",
    "        # Fallback: instala\u00e7\u00e3o manual\n",
    "        print(\"\u26a0\ufe0f  Instalando pacotes manualmente...\")\n",
    "        packages = [\"librosa\", \"soundfile\", \"gradio\", \"matplotlib\"]\n",
    "        for pkg in packages:\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg], check=True)\n",
    "            print(f\"  \u2713 {pkg}\")\n",
    "        print(\"\u2705 Instala\u00e7\u00e3o completa\")\n",
    "    \n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"\ud83d\udcbb Rodando localmente (usando ambiente Pixi)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcda Importar Bibliotecas\n",
    "\n",
    "Agora vamos importar as bibliotecas necess\u00e1rias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import gradio as gr\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "print(\"\u2705 Bibliotecas importadas com sucesso!\")\n",
    "print(f\"Librosa version: {librosa.__version__}\")\n",
    "print(f\"Gradio version: {gr.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfbc Gerar \u00c1udio Sint\u00e9tico\n",
    "\n",
    "Vamos criar um \u00e1udio de exemplo para demonstra\u00e7\u00e3o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par\u00e2metros\n",
    "sample_rate = 22050\n",
    "duration = 2.0  # segundos\n",
    "frequency = 440  # Hz (nota L\u00e1)\n",
    "\n",
    "# Gera um tom senoidal\n",
    "t = np.linspace(0, duration, int(sample_rate * duration))\n",
    "audio_signal = 0.5 * np.sin(2 * np.pi * frequency * t)\n",
    "\n",
    "# Adiciona um fade in/out\n",
    "fade_samples = int(0.1 * sample_rate)\n",
    "audio_signal[:fade_samples] *= np.linspace(0, 1, fade_samples)\n",
    "audio_signal[-fade_samples:] *= np.linspace(1, 0, fade_samples)\n",
    "\n",
    "print(f\"\u2705 \u00c1udio gerado: {duration}s @ {sample_rate} Hz\")\n",
    "print(f\"   Frequ\u00eancia: {frequency} Hz\")\n",
    "print(f\"   Shape: {audio_signal.shape}\")\n",
    "\n",
    "# Reproduz o \u00e1udio\n",
    "display(Audio(audio_signal, rate=sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca An\u00e1lise Espectral\n",
    "\n",
    "Vamos visualizar o espectrograma do \u00e1udio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a STFT (Short-Time Fourier Transform)\n",
    "D = librosa.stft(audio_signal)\n",
    "S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "\n",
    "# Visualiza o espectrograma\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.specshow(S_db, x_axis=\"time\", y_axis=\"hz\", sr=sample_rate, cmap=\"viridis\")\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.title(\"Espectrograma\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Shape do espectrograma: {S_db.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf An\u00e1lise de Caracter\u00edsticas\n",
    "\n",
    "Vamos extrair caracter\u00edsticas do \u00e1udio usando Librosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dura\u00e7\u00e3o\n",
    "duration_calc = librosa.get_duration(y=audio_signal, sr=sample_rate)\n",
    "\n",
    "# Tempo (BPM) - para um tom puro, pode n\u00e3o ser muito significativo\n",
    "tempo, beats = librosa.beat.beat_track(y=audio_signal, sr=sample_rate)\n",
    "\n",
    "# Zero Crossing Rate\n",
    "zcr = librosa.feature.zero_crossing_rate(audio_signal)\n",
    "\n",
    "# Spectral Centroid\n",
    "spectral_centroids = librosa.feature.spectral_centroid(y=audio_signal, sr=sample_rate)\n",
    "\n",
    "# MFCCs\n",
    "mfccs = librosa.feature.mfcc(y=audio_signal, sr=sample_rate, n_mfcc=13)\n",
    "\n",
    "print(\"\ud83d\udcca Caracter\u00edsticas Extra\u00eddas:\")\n",
    "print(f\"  Dura\u00e7\u00e3o: {duration_calc:.2f}s\")\n",
    "print(f\"  Tempo: {tempo:.2f} BPM\")\n",
    "print(f\"  Zero Crossing Rate (m\u00e9dia): {zcr.mean():.4f}\")\n",
    "print(f\"  Spectral Centroid (m\u00e9dia): {spectral_centroids.mean():.2f} Hz\")\n",
    "print(f\"  MFCCs shape: {mfccs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfa8 Interface Gradio Interativa\n",
    "\n",
    "Vamos criar uma interface web interativa com Gradio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_audio(audio_input):\n",
    "    \"\"\"\n",
    "    Analisa um arquivo de \u00e1udio e retorna informa\u00e7\u00f5es + espectrograma.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Processa o input\n",
    "        if isinstance(audio_input, tuple):\n",
    "            sr, y = audio_input\n",
    "            # Converte para mono se necess\u00e1rio\n",
    "            if len(y.shape) > 1:\n",
    "                y = np.mean(y, axis=1)\n",
    "            # Normaliza\n",
    "            y = y.astype(np.float32)\n",
    "            if y.max() > 1.0:\n",
    "                y = y / np.iinfo(np.int16).max\n",
    "        else:\n",
    "            y, sr = librosa.load(audio_input, sr=None)\n",
    "        \n",
    "        # An\u00e1lise\n",
    "        duration = librosa.get_duration(y=y, sr=sr)\n",
    "        tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y).mean()\n",
    "        centroid = librosa.feature.spectral_centroid(y=y, sr=sr).mean()\n",
    "        \n",
    "        # Espectrograma\n",
    "        D = librosa.stft(y)\n",
    "        S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 4))\n",
    "        librosa.display.specshow(S_db, x_axis=\"time\", y_axis=\"hz\", sr=sr, ax=ax, cmap=\"viridis\")\n",
    "        fig.colorbar(ax.collections[0], ax=ax, format=\"%+2.0f dB\")\n",
    "        ax.set_title(\"Espectrograma\")\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Resultado textual\n",
    "        result = f\"\"\"\n",
    "### \u2705 An\u00e1lise Completa!\n",
    "\n",
    "**\ud83d\udcca Informa\u00e7\u00f5es:**\n",
    "- Dura\u00e7\u00e3o: {duration:.2f}s\n",
    "- Taxa de Amostragem: {sr} Hz\n",
    "- Tempo Estimado: {tempo:.2f} BPM\n",
    "- Zero Crossing Rate: {zcr:.4f}\n",
    "- Spectral Centroid: {centroid:.2f} Hz\n",
    "        \"\"\"\n",
    "        \n",
    "        return result, fig\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"\u274c Erro: {str(e)}\", None\n",
    "\n",
    "\n",
    "# Cria a interface\n",
    "with gr.Blocks(title=\"Machine Listening Demo\") as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # \ud83c\udfb5 Machine Listening - Demo Interativa\n",
    "    Fa\u00e7a upload de um arquivo de \u00e1udio ou grave usando o microfone!\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        audio_input = gr.Audio(label=\"\u00c1udio\", type=\"filepath\", sources=[\"upload\", \"microphone\"])\n",
    "    \n",
    "    analyze_btn = gr.Button(\"\ud83d\udd0d Analisar\", variant=\"primary\")\n",
    "    \n",
    "    text_output = gr.Markdown()\n",
    "    plot_output = gr.Plot()\n",
    "    \n",
    "    analyze_btn.click(\n",
    "        fn=analyze_audio,\n",
    "        inputs=audio_input,\n",
    "        outputs=[text_output, plot_output]\n",
    "    )\n",
    "\n",
    "# Lan\u00e7a a interface (share=True para link p\u00fablico no Colab)\n",
    "demo.launch(share=IN_COLAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udf93 Conclus\u00e3o\n",
    "\n",
    "Parab\u00e9ns! Voc\u00ea completou o workshop b\u00e1sico de Machine Listening.\n",
    "\n",
    "### \ud83d\udcda Pr\u00f3ximos Passos:\n",
    "\n",
    "1. Experimente com seus pr\u00f3prios arquivos de \u00e1udio\n",
    "2. Explore outras features do Librosa ([documenta\u00e7\u00e3o](https://librosa.org/))\n",
    "3. Implemente classifica\u00e7\u00e3o de \u00e1udio com ML\n",
    "4. Crie visualiza\u00e7\u00f5es mais avan\u00e7adas\n",
    "\n",
    "### \ud83d\udd17 Recursos:\n",
    "\n",
    "- [Librosa Documentation](https://librosa.org/doc/latest/index.html)\n",
    "- [Gradio Documentation](https://www.gradio.app/docs/)\n",
    "- [Audio Signal Processing for ML](https://www.youtube.com/watch?v=iCwMQJnKk2c)\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Learning! \ud83c\udfa7\ud83c\udfb6**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}